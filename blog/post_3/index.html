<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Paper notes: TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</title>
    <link rel="stylesheet" href="/css/style.css" />
  </head>
  <body id="nightModeDiv">
    <header>
  <nav>
    <p class="logo">Just a thought</p>
  
    <div class="nav-list">
      <a href="/">Home</a>
      <a href="/about">About</a>
      <a href="/blog">Blog</a>
      <button id="nightModeButton" class="night-mode-btn">
        <svg style="width: 20px;" version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" xmlns:xlink="http://www.w3.org/1999/xlink" enable-background="new 0 0 512 512">
          <g>
            <g>
              <path d="m275.4,500.7c-135,0-244.7-109.8-244.7-244.7 1.06581e-14-134.9 109.8-244.7 244.7-244.7 8.2,0 16.4,0.4 24.6,1.2 7.2,0.7 13.5,5.2 16.5,11.7s2.4,14.2-1.6,20.2c-23,33.8-35.2,73.3-35.2,114.2 0,105 78.7,192.2 183.2,202.6 7.2,0.7 13.5,5.2 16.5,11.7 3.1,6.5 2.4,14.2-1.6,20.2-45.8,67.4-121.4,107.6-202.4,107.6zm-12.5-448c-106.5,6.5-191.2,95.2-191.2,203.3 1.42109e-14,112.3 91.4,203.7 203.7,203.7 56.4,0 109.6-23.4 147.8-63.7-46.2-11.7-88.1-36.8-120.8-72.6-41.1-45.2-63.8-103.6-63.8-164.6 0.1-37.1 8.4-73.2 24.3-106.1z"/>
            </g>
          </g>
        </svg>
      </button>
    </div>
  </nav>
  
</header>
    <div class="article-wrapper">
      <h1>Paper notes: TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</h1>
      <div class="paragraph text-sm" >
        <span>Published: Sat, Jan 13, 2024</span>
        |
        <span>Last Modified: Wed, Feb 28, 2024</span>
      </div>
      <article class="paragraph text-md"><p>In terms of neural network models, the two size extremes: the gargantuan and the infinitesimal, are both where the cutting edge research is interested in.</p>
<p>I recently came across an interesting small language model (SLM) called TinyStories because of work:</p>
<p>Model card (33M variant): <a href="https://huggingface.co/roneneldan/TinyStories-33M">TinyStories-33M</a></p>
<p>Paper: <a href="https://arxiv.org/abs/2305.07759">TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</a> (Eldan and Li, 2023)</p>
<p>This post are some rough notes.</p>
<h2>Main contributions:</h2>
<h3>A new dataset(s) for SLM</h3>
<p>Uses GPT3.5 and GPT4 to generate a synthetic dataset TinyStories that are 2-3 paragraphs of short stories using vocabulary a 3-4 year old can understand.
Additionally trained a variant TinyStories-Instruct, which can be used for instruction following (e.g. summarising texts)</p>
<h3>Pretrained SLM</h3>
<p>Trains a range of SLM (small language models) ranging from 1 transformer layer, 1M params to 4 layers, 33M params. They generate more coherent English texts than larger models like GPT-2 or GPT-Neo (100M and above)</p>
<p>This showed that smaller models can still learn language and have emergence properties (factual knowledge, reasoning, context tracking), but only if trained on simpler texts.</p>
<h3>New Language Model Evaluation paradigm</h3>
<p>Introduces a paradigm of evaluation (small) language models using larger LMs like GPT4, which can have a richer scoring scheme than existing benchmarks for LMs</p>
<h3>Suggestive evidence on interpretability of SLM</h3>
<p>Suggests that smaller models like these are more interpretable than larger models. They also include some preliminary findings (only suggestive):</p>
<ul>
<li>Model width (embedding size) impacts syntax, grammar and factual knowledge more</li>
<li>Model depth (number of transformer layers) impacts consistency, context tracking more</li>
<li>Grammar is the easiest to learn (plateaued), followed by consistency, and then creativity (which never plateaued in these models / continue to improve as model size increases)</li>
<li>Looked into interpretability of the attention heads and neurons in the MLPs in a single transformer layer tiny story model
<ul>
<li>
<p>Found some evidence that attention heads specialise into 2 groups: local attentions (for tokens serving grammatical purposes) and global attentions (for tokens serving semantic purposes)</p>
</li>
<li>
<p>Found some evidence that MLP neurons specialise into specific functions (e.g. noun neurons, adjective neurons, name neurons etc.) in contrast with GPT-2's neurons which don't seem to converge to specific functions</p>
</li>
</ul>
</li>
</ul>
<h3>Suggestive evidence on hyperparameter tuning</h3>
<p>Suggests smaller models can be used for hyperparameter tuning
Found some evidence to back up the polynomial scaling law between the model size and learning budget for LLMs</p>
</article>
    </div>
    <footer>
</footer>
    <script src="/js/script.js"></script>
    
  </body>
</html>